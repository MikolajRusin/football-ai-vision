{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is responsible for downloading and preparing datasets from various source. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> 5 videos from Google Drive (which will be split into frames)  \n",
    "---> dataset from roboflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define path of the project and the paths where the train/valid/test sets will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\n",
      "|\n",
      "|--data -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\n",
      "|  |--images -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\train\n",
      "|  |   |--train -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\train\n",
      "|  |   |--valid -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\valid\n",
      "|  |   |--test -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\test\n",
      "|  |   \n",
      "|  |--origin_videos -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\origin_videos\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Path of the project\n",
    "PROJECT_PATH = Path(os.getcwd()).resolve().parent\n",
    "\n",
    "# Make the main data dir\n",
    "DATA_PATH = PROJECT_PATH / 'data'\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Make the dir where train/valid/test set will be saved\n",
    "IMAGES_PATH = DATA_PATH / 'images'\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Make the train dir\n",
    "TRAIN_PATH = IMAGES_PATH / 'train'\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "\n",
    "# Make the valid dir\n",
    "VALID_PATH = IMAGES_PATH / 'valid'\n",
    "os.makedirs(VALID_PATH, exist_ok=True)\n",
    "\n",
    "# Make the test dir\n",
    "TEST_PATH = IMAGES_PATH / 'test'\n",
    "os.makedirs(TEST_PATH, exist_ok=True)\n",
    "\n",
    "# Make the dir where the original videos will be stored\n",
    "ORIGIN_VIDEOS_PATH = DATA_PATH / 'origin_videos'\n",
    "os.makedirs(ORIGIN_VIDEOS_PATH, exist_ok=True)\n",
    "\n",
    "print(f'Project path -> {PROJECT_PATH}')\n",
    "print(f'|')\n",
    "print(f'|--data -> {DATA_PATH}')\n",
    "print(f'|  |--images -> {TRAIN_PATH}')\n",
    "print(f'|  |   |--train -> {TRAIN_PATH}')\n",
    "print(f'|  |   |--valid -> {VALID_PATH}')\n",
    "print(f'|  |   |--test -> {TEST_PATH}')\n",
    "print(f'|  |   ')\n",
    "print(f'|  |--origin_videos -> {ORIGIN_VIDEOS_PATH}')\n",
    "print(f'|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing videos from Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download videos from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\n",
      "To: C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\origin_videos\\0bfacc_0.mp4\n",
      "\n",
      "  0%|          | 0.00/19.9M [00:00<?, ?B/s]\n",
      "  3%|▎         | 524k/19.9M [00:00<00:05, 3.78MB/s]\n",
      " 13%|█▎        | 2.62M/19.9M [00:00<00:01, 11.8MB/s]\n",
      " 37%|███▋      | 7.34M/19.9M [00:00<00:00, 25.0MB/s]\n",
      " 50%|█████     | 9.96M/19.9M [00:00<00:00, 21.4MB/s]\n",
      " 63%|██████▎   | 12.6M/19.9M [00:00<00:00, 22.7MB/s]\n",
      " 84%|████████▍ | 16.8M/19.9M [00:00<00:00, 27.0MB/s]\n",
      "100%|██████████| 19.9M/19.9M [00:00<00:00, 26.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\n",
      "To: C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\origin_videos\\2e57b9_0.mp4\n",
      "\n",
      "  0%|          | 0.00/21.1M [00:00<?, ?B/s]\n",
      "  2%|▏         | 524k/21.1M [00:00<00:04, 4.12MB/s]\n",
      " 12%|█▏        | 2.62M/21.1M [00:00<00:01, 12.4MB/s]\n",
      " 37%|███▋      | 7.86M/21.1M [00:00<00:00, 27.7MB/s]\n",
      " 52%|█████▏    | 11.0M/21.1M [00:00<00:00, 25.0MB/s]\n",
      " 72%|███████▏  | 15.2M/21.1M [00:00<00:00, 26.4MB/s]\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 29.5MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\n",
      "To: C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\origin_videos\\08fd33_0.mp4\n",
      "\n",
      "  0%|          | 0.00/19.9M [00:00<?, ?B/s]\n",
      "  3%|▎         | 524k/19.9M [00:00<00:05, 3.74MB/s]\n",
      " 13%|█▎        | 2.62M/19.9M [00:00<00:01, 11.8MB/s]\n",
      " 40%|███▉      | 7.86M/19.9M [00:00<00:00, 27.0MB/s]\n",
      " 55%|█████▌    | 11.0M/19.9M [00:00<00:00, 24.4MB/s]\n",
      " 71%|███████   | 14.2M/19.9M [00:00<00:00, 26.5MB/s]\n",
      "100%|██████████| 19.9M/19.9M [00:00<00:00, 29.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\n",
      "To: C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\origin_videos\\573e61_0.mp4\n",
      "\n",
      "  0%|          | 0.00/18.9M [00:00<?, ?B/s]\n",
      "  3%|▎         | 524k/18.9M [00:00<00:04, 4.37MB/s]\n",
      " 14%|█▍        | 2.62M/18.9M [00:00<00:01, 12.4MB/s]\n",
      " 42%|████▏     | 7.86M/18.9M [00:00<00:00, 27.5MB/s]\n",
      " 58%|█████▊    | 11.0M/18.9M [00:00<00:00, 25.2MB/s]\n",
      " 75%|███████▍  | 14.2M/18.9M [00:00<00:00, 27.1MB/s]\n",
      "100%|██████████| 18.9M/18.9M [00:00<00:00, 28.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\n",
      "To: C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\origin_videos\\121364_0.mp4\n",
      "\n",
      "  0%|          | 0.00/17.2M [00:00<?, ?B/s]\n",
      "  3%|▎         | 524k/17.2M [00:00<00:04, 3.95MB/s]\n",
      " 15%|█▌        | 2.62M/17.2M [00:00<00:01, 12.7MB/s]\n",
      " 43%|████▎     | 7.34M/17.2M [00:00<00:00, 27.2MB/s]\n",
      " 61%|██████    | 10.5M/17.2M [00:00<00:00, 23.1MB/s]\n",
      " 76%|███████▌  | 13.1M/17.2M [00:00<00:00, 24.0MB/s]\n",
      "100%|██████████| 17.2M/17.2M [00:00<00:00, 27.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/0bfacc_0.mp4\" \"https://drive.google.com/uc?id=12TqauVZ9tLAv8kWxTTBFWtgt2hNQ4_ZF\"\n",
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/2e57b9_0.mp4\" \"https://drive.google.com/uc?id=19PGw55V8aA6GZu5-Aac5_9mCy3fNxmEf\"\n",
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/08fd33_0.mp4\" \"https://drive.google.com/uc?id=1OG8K6wqUw9t7lp9ms1M48DxRhwTYciK-\"\n",
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/573e61_0.mp4\" \"https://drive.google.com/uc?id=1yYPKuXbHsCxqjA9G-S6aeR2Kcnos8RPU\"\n",
    "!gdown -O \"{ORIGIN_VIDEOS_PATH}/121364_0.mp4\" \"https://drive.google.com/uc?id=1vVwjW1dE1drIdd4ZSILfbCGPD4weoNiu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract frames from videos and move them to appropriate directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting frames from the videos will involve going through it at a certain frequency of frame extraction. The frame extraction frequency is defineed in the variable STRIDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each frame will be saved as .jpg format and will have a unique index, for example: image_0341.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import supervision as sv\n",
    "import cv2\n",
    "\n",
    "# ----------------------------------------------------EXTRACTING FRAMES FROM VIDEOS----------------------------------------------------\n",
    "def extract_frames(video_path: Path, output_path: Path, start_idx: int=0, stride=5) -> None:\n",
    "    '''\n",
    "    Extracts frames from the provided video and saves them as .jpg files with unique indexes\n",
    "    (e.g. image_0341.jpg), starting from a given index and at a specific frequency (stride).\n",
    "\n",
    "    Args:\n",
    "        video_path (Path): Path to the video file which frames will be extracted.\n",
    "        output_path (Path): Path to the output directory where the frames will be saved.\n",
    "        start_idx (int): The starting index for naming the output frames. For example, if start_idx=0, the first frame will be saved as image_0000.jpg. Defaults to 0.\n",
    "        stride (int): The frequency of frame extraction. For example, if stride=5, every 5th frame will be extracted. Defaults to 5.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Information about video\n",
    "    video_info = sv.VideoInfo.from_video_path(video_path)\n",
    "    # Generator of the video frames\n",
    "    frame_generator = sv.get_video_frames_generator(video_path, stride=stride)\n",
    "\n",
    "    frame_idx = start_idx # Starting index\n",
    "    current_video = str(video_path).split('\\\\')[-1]  # Get the video file name\n",
    "    # Process every STRIDE frame\n",
    "    for frame in tqdm(frame_generator, desc=f'Extracting frames from video -> {current_video}', total=int(video_info.total_frames / 5)):\n",
    "        output_frame_path = output_path / f'image_{frame_idx:04d}.jpg'  # Output path of the particular frame\n",
    "        cv2.imwrite(output_frame_path, frame)  # Save the frame\n",
    "\n",
    "        frame_idx += 1  # Increment index\n",
    "# ----------------------------------------------------EXTRACTING FRAMES FROM VIDEOS----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frames from video -> 08fd33_0.mp4: 100%|██████████| 150/150 [00:06<00:00, 24.15it/s]\n",
      "Extracting frames from video -> 0bfacc_0.mp4: 100%|██████████| 150/150 [00:06<00:00, 24.30it/s]\n",
      "Extracting frames from video -> 121364_0.mp4: 100%|██████████| 150/150 [00:06<00:00, 24.61it/s]\n",
      "Extracting frames from video -> 2e57b9_0.mp4: 100%|██████████| 150/150 [00:06<00:00, 22.93it/s]\n",
      "Extracting frames from video -> 573e61_0.mp4: 100%|██████████| 150/150 [00:06<00:00, 23.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750 images from videos were saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make the dir where the extracted frames will be saved\n",
    "EXTRACTED_FRAMES_DIR = 'extracted_frames'\n",
    "EXTRACTED_FRAMES_PATH = DATA_PATH / EXTRACTED_FRAMES_DIR\n",
    "os.makedirs(EXTRACTED_FRAMES_PATH, exist_ok=True)\n",
    "\n",
    "STRIDE = 5  # Frequency of frame extraction\n",
    "start_idx_videos = []  # List to store starting indices for each video\n",
    "\n",
    "# Process every video in ORIGIN_VIDEOS_PATH directory\n",
    "for video_file_name in os.listdir(ORIGIN_VIDEOS_PATH):\n",
    "    video_path = ORIGIN_VIDEOS_PATH / video_file_name  # Absolute path to the current video\n",
    "    # Calculate the starting index based on the number of frames already extracted\n",
    "    start_idx = len(os.listdir(EXTRACTED_FRAMES_PATH))\n",
    "    start_idx_videos.append(start_idx)\n",
    "\n",
    "    # Extract frames from the current video\n",
    "    extract_frames(video_path, EXTRACTED_FRAMES_PATH, start_idx, STRIDE)\n",
    "\n",
    "# After processing all videos, display the total number of saved frames\n",
    "print(f'{len(os.listdir(EXTRACTED_FRAMES_PATH))} images from videos were saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 150, 300, 450, 600]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the starting indices for each video\n",
    "start_idx_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train, valid and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load and sort file names of the extracted frames\n",
    "sorted_file_names = sorted(os.listdir(EXTRACTED_FRAMES_PATH))\n",
    "np_file_names = np.array(sorted_file_names)  # Numpy array of the file names of frames\n",
    "image_ids = np.arange(len(np_file_names))  # Indices of the file names\n",
    "bins = start_idx_videos[1:]  # Bins of the video ranges\n",
    "\n",
    "# Create video_mask based on the bins, using np.digitize to assign each frame to its respective video\n",
    "# E.g. video 1 has 5 frames, so the indices of the frames will be (0, 1, 2, 3, 4), video 2 (5, 6, 7, 8, 9)\n",
    "# The mask for these videos is (0, 0, 0, 0, 0, 1, 1, 1, 1, 1)\n",
    "video_mask = np.digitize(image_ids, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 0: 150 images\n",
      "Video 1: 150 images\n",
      "Video 2: 150 images\n",
      "Video 3: 150 images\n",
      "Video 4: 150 images\n"
     ]
    }
   ],
   "source": [
    "# Show the number of frames for each video\n",
    "video_ids, counts = np.unique(video_mask, return_counts=True)\n",
    "\n",
    "for n_video, count in zip(video_ids, counts):\n",
    "    print(f'Video {n_video}: {count} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "VALID_SIZE = 0.1  # Set ratio for valid samples\n",
    "TEST_SIZE = 0.1  # Set ratio for test samples\n",
    "\n",
    "# Make the valid set\n",
    "train_full_images, valid_images, train_full_mask, valid_mask = train_test_split(np_file_names, video_mask, test_size=VALID_SIZE, stratify=video_mask)\n",
    "# Make the train and test set\n",
    "train_images, test_images, train_mask, test_mask = train_test_split(train_full_images, train_full_mask, test_size=TEST_SIZE, stratify=train_full_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "Video 0: 122 images\n",
      "Video 1: 121 images\n",
      "Video 2: 121 images\n",
      "Video 3: 121 images\n",
      "Video 4: 122 images\n",
      "Total Train Images: 607\n",
      "\n",
      "Valid Set\n",
      "Video 0: 15 images\n",
      "Video 1: 15 images\n",
      "Video 2: 15 images\n",
      "Video 3: 15 images\n",
      "Video 4: 15 images\n",
      "Total Valid Images: 75\n",
      "\n",
      "Test Set\n",
      "Video 0: 13 images\n",
      "Video 1: 14 images\n",
      "Video 2: 14 images\n",
      "Video 3: 14 images\n",
      "Video 4: 13 images\n",
      "Total Test Images: 68\n"
     ]
    }
   ],
   "source": [
    "print('Train Set')\n",
    "video_ids, train_counts = np.unique(train_mask, return_counts=True)\n",
    "for n_video, count in zip(video_ids, train_counts):\n",
    "    print(f'Video {n_video}: {count} images')\n",
    "print(f'Total Train Images: {len(train_mask)}')\n",
    "\n",
    "print('\\nValid Set')\n",
    "video_ids, valid_counts = np.unique(valid_mask, return_counts=True)\n",
    "for n_video, count in zip(video_ids, valid_counts):\n",
    "    print(f'Video {n_video}: {count} images')\n",
    "print(f'Total Valid Images: {len(valid_mask)}')\n",
    "\n",
    "print('\\nTest Set')\n",
    "video_ids, test_counts = np.unique(test_mask, return_counts=True)\n",
    "for n_video, count in zip(video_ids, test_counts):\n",
    "    print(f'Video {n_video}: {count} images')\n",
    "print(f'Total Test Images: {len(test_mask)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving the train, valid and test set to the appropriate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# ----------------------------------------------------MOVING IMAGES TO APPROPRIATE FOLDER----------------------------------------------------\n",
    "def move_images(image_paths_list: list[Path], target_folder_path: Path) -> None:\n",
    "    '''\n",
    "    Moves images from the current folder to the target folder. It checks if the image files \n",
    "    have a \".jpg\" extension and then moves them to the specified target folder.\n",
    "\n",
    "    Args:\n",
    "        image_paths_list (list[Path]): A list of 'Path' objects, where each path refers to an image file \n",
    "                                       that should be moved. The images should be in `.jpg` format.\n",
    "        target_folder_path (Path): The 'Path' object representing the target folder where the images \n",
    "                                    will be moved. The target folder should already exist.\n",
    "    '''\n",
    "    # Iterate through each image path in the list\n",
    "    for image_path in tqdm(image_paths_list, desc=f'Transferring images to {target_folder_path}', total=len(image_paths_list)):\n",
    "        # Check if the file is in the appropriate format '.jpg'\n",
    "        if str(image_path).endswith('.jpg'):\n",
    "            # Absolute path for the output image\n",
    "            output_image_path = target_folder_path / str(image_path).split('\\\\')[-1]\n",
    "\n",
    "            # Move the image from the source to the target foler\n",
    "            shutil.move(image_path, output_image_path)\n",
    "# ----------------------------------------------------MOVING IMAGES TO APPROPRIATE FOLDER----------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transferring images to C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\train: 100%|██████████| 607/607 [00:00<00:00, 1312.91it/s]\n",
      "Transferring images to C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\valid: 100%|██████████| 75/75 [00:00<00:00, 1511.40it/s]\n",
      "Transferring images to C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\test: 100%|██████████| 68/68 [00:00<00:00, 1243.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create image sets (paths to each image)\n",
    "image_sets = [\n",
    "    [EXTRACTED_FRAMES_PATH / train_image for train_image in train_images],  # Train set\n",
    "    [EXTRACTED_FRAMES_PATH / valid_image for valid_image in valid_images],  # Valid set\n",
    "    [EXTRACTED_FRAMES_PATH / test_image for test_image in test_images]      # Test set\n",
    "]\n",
    "target_folder_sets = [TRAIN_PATH, VALID_PATH, TEST_PATH]  # List of paths for the corresponding sets\n",
    "\n",
    "# Iterate through set of images and corresponding target folder\n",
    "for image_set, target_folder_set in zip(image_sets, target_folder_sets):\n",
    "    move_images(image_paths_list=image_set, target_folder_path=target_folder_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The created directory 'extracted_frames' is no longer needed, so we can delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(EXTRACTED_FRAMES_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing datasets from Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download roboflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in football-ai-vision-1 to coco:: 100%|██████████| 83381/83381 [00:03<00:00, 24614.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to football-ai-vision-1 in coco:: 100%|██████████| 380/380 [00:00<00:00, 1272.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Load API Keys from .env file\n",
    "load_dotenv()\n",
    "# Get the Roboflow API Key\n",
    "ROBOFLOW_API_KEY = os.getenv('ROBOFLOW_API_KEY')\n",
    "\n",
    "# Change the current dir to the data directory\n",
    "HOME = Path(os.getcwd())\n",
    "os.chdir(DATA_PATH)\n",
    "\n",
    "# Download dataset\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace(\"mikoaj-bu1z8\").project(\"football-ai-vision\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"coco\")\n",
    "\n",
    "# Return to the Home direcotry\n",
    "os.chdir(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving the train, valid and test set to the appropriate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transferring images to C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\train: 100%|██████████| 299/299 [00:00<00:00, 689.20it/s]\n",
      "Transferring images to C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\valid: 100%|██████████| 50/50 [00:00<00:00, 1366.81it/s]\n",
      "Transferring images to C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\test: 100%|██████████| 26/26 [00:00<00:00, 843.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Name of directories for train, valid and test set\n",
    "TRAIN_DIR = 'train'\n",
    "VALID_DIR = 'valid'\n",
    "TEST_DIR = 'test'\n",
    "\n",
    "# Create image sets (paths to each image)\n",
    "image_sets = [\n",
    "    [Path(dataset.location) / TRAIN_DIR / train_image for train_image in os.listdir(Path(dataset.location) / TRAIN_DIR)],  # Train set\n",
    "    [Path(dataset.location) / VALID_DIR / valid_image for valid_image in os.listdir(Path(dataset.location) / VALID_DIR)],  # Valid set\n",
    "    [Path(dataset.location) / TEST_DIR / test_image for test_image in os.listdir(Path(dataset.location) / TEST_DIR)]       # Test set\n",
    "]\n",
    "target_folder_sets = [TRAIN_PATH, VALID_PATH, TEST_PATH]  # List of paths for the corresponding sets\n",
    "\n",
    "# Iterate through set of images and corresponding target folder\n",
    "for image_set, target_folder_set in zip(image_sets, target_folder_sets):\n",
    "    move_images(image_paths_list=image_set, target_folder_path=target_folder_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded directory from Roboflow is no longer needed, so we can delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(dataset.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project data structure after this section should look like this\n",
    "\n",
    "```\n",
    "Project path  \n",
    "|  \n",
    "|--data  \n",
    "|  |--images  \n",
    "|  |  |--train (905 images)  \n",
    "|  |  |--valid (124 images)  \n",
    "|  |  |--test (93 images)  \n",
    "|  |   \n",
    "|  |--origin_videos (5 videos)  \n",
    "|\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\n",
      "|\n",
      "|--data -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\n",
      "|  |--images -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\train\n",
      "|  |   |--train (905 images) -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\train\n",
      "|  |   |--valid (124 images) -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\valid\n",
      "|  |   |--test  (93 iamges) -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\images\\test\n",
      "|  |   \n",
      "|  |--origin_videos (5 videos) -> C:\\Users\\miki0\\OneDrive\\Pulpit\\Projects\\my_projects\\FootballAI\\data\\origin_videos\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "n_train_images = len(os.listdir(TRAIN_PATH))\n",
    "n_valid_images = len(os.listdir(VALID_PATH))\n",
    "n_test_images = len(os.listdir(TEST_PATH))\n",
    "n_videos = len(os.listdir(ORIGIN_VIDEOS_PATH))\n",
    "\n",
    "print(f'Project path -> {PROJECT_PATH}')\n",
    "print(f'|')\n",
    "print(f'|--data -> {DATA_PATH}')\n",
    "print(f'|  |--images -> {TRAIN_PATH}')\n",
    "print(f'|  |   |--train ({n_train_images} images) -> {TRAIN_PATH}')\n",
    "print(f'|  |   |--valid ({n_valid_images} images) -> {VALID_PATH}')\n",
    "print(f'|  |   |--test  ({n_test_images} iamges) -> {TEST_PATH}')\n",
    "print(f'|  |   ')\n",
    "print(f'|  |--origin_videos ({n_videos} videos) -> {ORIGIN_VIDEOS_PATH}')\n",
    "print(f'|')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
